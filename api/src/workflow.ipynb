{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangGraph implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Anaqi_Amir/opt/anaconda3/envs/FlavorFusion/lib/python3.11/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "from nlp.NLSPipeline import extract_nutritional_features\n",
    "from models.dev.faiss_indexes import FlatIndex\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from typing import Dict, List, Dict, Any, Optional, TypedDict\n",
    "\n",
    "# from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Load env\n",
    "load_dotenv()\n",
    "\n",
    "# Load index\n",
    "index = FlatIndex(\"../../recipe_embeddings.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Code\n",
    "Works but no input loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your tools\n",
    "@tool\n",
    "def recommend_recipes(q: str) -> str:\n",
    "    \"\"\"Takes in user input, extracts relevant features, and output recommended recipes from database\"\"\"\n",
    "\n",
    "    print(f\"\\n Parsed user input: \\n {q} \\n\")\n",
    "\n",
    "    extracted_features = extract_nutritional_features(q)\n",
    "\n",
    "    print(f\"\\n Extracted features: \\n {extracted_features} \\n\")\n",
    "\n",
    "    recs = index.recommend_recipes(\n",
    "        user_ingredients=extracted_features.user_ingredients,\n",
    "        allergens=extracted_features.allergens,\n",
    "        calories=extracted_features.calories,\n",
    "        total_fat=extracted_features.total_fat,\n",
    "        protein=extracted_features.protein,\n",
    "        saturated_fat=extracted_features.saturated_fat,\n",
    "        carbs=extracted_features.carbs,\n",
    "        sodium=extracted_features.sodium,\n",
    "        sugar=extracted_features.sugar,\n",
    "        top_n=10,\n",
    "    )\n",
    "\n",
    "    print(f\"\\n recs: \\n {recs} \\n\")\n",
    "\n",
    "    return \", \".join(recs)\n",
    "\n",
    "\n",
    "@tool\n",
    "def final_answer(answer: str) -> str:\n",
    "    \"\"\"Useful for providing the final answer to the user.\"\"\"\n",
    "    return answer\n",
    "\n",
    "\n",
    "tools = [recommend_recipes, final_answer]\n",
    "\n",
    "# Define the LLM\n",
    "llm = ChatOpenAI(temperature=0.7)\n",
    "\n",
    "# Define the agent\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            You are a recipe recommendation program that takes in user inputs\n",
    "            and outputs a list of recipes. If a user does not provide enough information\n",
    "            on what recipes they want, you will keep on asking them about it until\n",
    "            you have enough information to get a good recommendation for the user.\n",
    "            \"\"\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{query}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")\n",
    "agent = create_tool_calling_agent(llm=llm, prompt=prompt, tools=tools)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "\n",
    "# Define the LangGraph state\n",
    "class AgentState(TypedDict):\n",
    "    messages: List[Any]\n",
    "    ingredients: Optional[str]\n",
    "    nutrition: Optional[str]\n",
    "    recipes: Optional[str]\n",
    "\n",
    "\n",
    "# Define the nodes\n",
    "def agent_node(state: AgentState) -> Dict:\n",
    "    query = state[\"messages\"][-1]\n",
    "    chat_history = state[\"messages\"][:1]\n",
    "    print(f\"agent_node: query = {query}\")\n",
    "    print(f\"agent_node: chat_history = {chat_history}\")\n",
    "    result = agent_executor.invoke({\"query\": query, \"chat_history\": chat_history})\n",
    "    print(f\"agent_node: result = {result}\")\n",
    "    output = {\"messages\": state[\"messages\"] + [AIMessage(content=result[\"output\"])]}\n",
    "    print(f\"agent_node: output = {output}\")\n",
    "    return output\n",
    "\n",
    "\n",
    "def recommendation_node(state: AgentState):\n",
    "    print(f\"recommend_node: state = {state}\")\n",
    "    result = recommend_recipes.run(\n",
    "        ingredients=state[\"ingredients\"], nutrition=state[\"nutrition\"]\n",
    "    )\n",
    "    return {\n",
    "        \"messages\": state[\"messages\"]\n",
    "        + [AIMessage(content=f\"Here are some recommended recipes: {result}\")],\n",
    "        \"recipes\": result,\n",
    "    }\n",
    "\n",
    "\n",
    "def final_answer_node(state: AgentState) -> Dict:\n",
    "    print(f\"final_answer_node: state = {state}\")\n",
    "    result = final_answer.run(answer=state[\"messages\"][-1])\n",
    "    return {\"messages\": state[\"messages\"] + [AIMessage(content=result)]}\n",
    "\n",
    "\n",
    "# Define router\n",
    "def router(state: AgentState):\n",
    "    if \"recommend_recipes\" in state[\"messages\"][-1]:\n",
    "        return \"recommend\"\n",
    "    elif \"final_answer\" in state[\"messages\"][-1]:\n",
    "        return \"final\"\n",
    "    else:\n",
    "        return \"agent\"\n",
    "\n",
    "\n",
    "# Define the graph\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"agent\", agent_node)\n",
    "workflow.add_node(\"recommendation_tool\", recommendation_node)\n",
    "workflow.add_node(\"final_answer_tool\", final_answer_node)\n",
    "\n",
    "# Set up the edges\n",
    "workflow.add_edge(START, \"agent\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    router,\n",
    "    {\n",
    "        \"recommend\": \"recommendation_tool\",\n",
    "        \"final\": \"final_answer_tool\",\n",
    "        \"agent\": \"agent\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"recommendation_tool\", \"agent\")\n",
    "workflow.add_edge(\"final_answer_tool\", END)\n",
    "\n",
    "# Compile the graph\n",
    "app = workflow.compile()\n",
    "\n",
    "# Example usage\n",
    "# inputs = {\n",
    "#     \"messages\": [\n",
    "#         HumanMessage(\n",
    "#             content=\"I'm looking for healthy recipes with chicken and low carbs.\"\n",
    "#         )\n",
    "#     ],\n",
    "#     \"ingredients\": \"chicken, garlic, honey\",\n",
    "#     \"nutrition\": \"High protein\",\n",
    "#     \"recipes\": \"Honey garlic chicken\",\n",
    "# }\n",
    "inputs = AgentState(\n",
    "    # messages=[\"I'm looking for healthy recipes with chicken and low carbs\"]\n",
    "    messages=[\n",
    "        \"Please recommend recipes that are healthy are have chicken. I want it to have low carbs too.\"\n",
    "    ]\n",
    ")\n",
    "result = app.invoke(inputs)\n",
    "print(result)\n",
    "\n",
    "# inputs2 = {\"messages\": [HumanMessage(content=\"Hi, how are you?\")]}\n",
    "# result2 = app.invoke(inputs2)\n",
    "# print(result2)\n",
    "\n",
    "# inputs3 = {\"messages\": [HumanMessage(content=\"I need recipes with beef and high protein\")]}\n",
    "# result3 = app.invoke(inputs3)\n",
    "# print(result3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(app.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Loop but No Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Hello! How can I assist you today?\n",
      "Assistant: \n",
      "\n",
      " Parsed user input: \n",
      " high protein chicken recipes with rice or potatoes \n",
      "\n",
      "\n",
      " Extracted features: \n",
      " user_ingredients=['chicken', 'rice', 'potatoes'] allergens=[] calories=None total_fat=None saturated_fat=None carbs=None sugar=None sodium=None protein=None \n",
      "\n",
      "Assistant: Error: TypeError('cannot unpack non-iterable NoneType object')\n",
      " Please fix your mistakes.\n",
      "Assistant: I encountered an error while trying to retrieve the recommended recipes. Let me try again.\n",
      "\n",
      " Parsed user input: \n",
      " high protein chicken with rice \n",
      "\n",
      "\n",
      " Parsed user input: \n",
      " high protein chicken with potatoes \n",
      "\n",
      "\n",
      " Extracted features: \n",
      " user_ingredients=['chicken', 'rice'] allergens=[] calories=None total_fat=None saturated_fat=None carbs=None sugar=None sodium=None protein=(20.0, 30.0) \n",
      "\n",
      "\n",
      " Extracted features: \n",
      " user_ingredients=['chicken', 'potatoes'] allergens=[] calories=None total_fat=None saturated_fat=None carbs=None sugar=None sodium=None protein=(20.0, 30.0) \n",
      "\n",
      "Assistant: Error: TypeError('cannot unpack non-iterable NoneType object')\n",
      " Please fix your mistakes.\n",
      "Assistant: I encountered an error while trying to retrieve the recommended recipes for high protein chicken recipes with rice and potatoes. Let me try again with a different approach.\n",
      "\n",
      " Parsed user input: \n",
      " high protein chicken recipes \n",
      "\n",
      "\n",
      " Parsed user input: \n",
      " chicken with rice recipes \n",
      "\n",
      "\n",
      " Parsed user input: \n",
      " chicken with potatoes recipes \n",
      "\n",
      "\n",
      " Extracted features: \n",
      " user_ingredients=['chicken', 'rice'] allergens=[] calories=(None, None) total_fat=(None, None) saturated_fat=(None, None) carbs=(None, None) sugar=(None, None) sodium=(None, None) protein=(None, None) \n",
      "\n",
      "\n",
      " Extracted features: \n",
      " user_ingredients=['chicken', 'potatoes'] allergens=[] calories=None total_fat=None saturated_fat=None carbs=None sugar=None sodium=None protein=None \n",
      "\n",
      "\n",
      " Extracted features: \n",
      " user_ingredients=['chicken'] allergens=['null'] calories=(None, None) total_fat=(None, None) saturated_fat=(None, None) carbs=(None, None) sugar=(None, None) sodium=(None, None) protein=(None, None) \n",
      "\n",
      "\n",
      " recs: \n",
      " ['old fashioned chicken noodle soup', 'feel better chicken noodle soup', 'corn and  broccoli bake', 'grandma s chicken and rice soup', 'swanson sensational chicken noodle soup', 'minnesota cream of chicken   wild rice soup', 'chicken rice hot dish', 'easy swanson chicken noodle soup', 'chicken tortilla soup  quick', 'creamy slow cooker chicken'] \n",
      "\n",
      "\n",
      " recs: \n",
      " ['old fashioned chicken noodle soup', 'feel better chicken noodle soup', 'corn and  broccoli bake', 'grandma s chicken and rice soup', 'swanson sensational chicken noodle soup', 'minnesota cream of chicken   wild rice soup', 'chicken rice hot dish', 'easy swanson chicken noodle soup', 'chicken tortilla soup  quick', 'creamy slow cooker chicken'] \n",
      "\n",
      "Assistant: Error: TypeError('cannot unpack non-iterable NoneType object')\n",
      " Please fix your mistakes.\n",
      "Assistant: I have found some recommended recipes for you:\n",
      "\n",
      "1. Old Fashioned Chicken Noodle Soup\n",
      "2. Feel Better Chicken Noodle Soup\n",
      "3. Corn and Broccoli Bake\n",
      "4. Grandma's Chicken and Rice Soup\n",
      "5. Swanson Sensational Chicken Noodle Soup\n",
      "6. Minnesota Cream of Chicken and Wild Rice Soup\n",
      "7. Chicken Rice Hot Dish\n",
      "8. Easy Swanson Chicken Noodle Soup\n",
      "9. Chicken Tortilla Soup (Quick)\n",
      "10. Creamy Slow Cooker Chicken\n",
      "\n",
      "I hope you find these options appealing!\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "\n",
    "\n",
    "# Define tools\n",
    "@tool\n",
    "def recommend_recipes(q: str) -> str:\n",
    "    \"\"\"Takes in user input, extracts relevant features, and output recommended recipes from database\"\"\"\n",
    "\n",
    "    print(f\"\\n Parsed user input: \\n {q} \\n\")\n",
    "\n",
    "    extracted_features = extract_nutritional_features(q)\n",
    "\n",
    "    print(f\"\\n Extracted features: \\n {extracted_features} \\n\")\n",
    "\n",
    "    recs = index.recommend_recipes(\n",
    "        user_ingredients=extracted_features.user_ingredients,\n",
    "        allergens=extracted_features.allergens,\n",
    "        calories=extracted_features.calories,\n",
    "        total_fat=extracted_features.total_fat,\n",
    "        protein=extracted_features.protein,\n",
    "        saturated_fat=extracted_features.saturated_fat,\n",
    "        carbs=extracted_features.carbs,\n",
    "        sodium=extracted_features.sodium,\n",
    "        sugar=extracted_features.sugar,\n",
    "        top_n=10,\n",
    "    )\n",
    "\n",
    "    print(f\"\\n recs: \\n {recs} \\n\")\n",
    "\n",
    "    return \", \".join(recs)\n",
    "\n",
    "\n",
    "@tool\n",
    "def final_answer(answer: str) -> str:\n",
    "    \"\"\"Useful for providing the final answer to the user.\"\"\"\n",
    "    print(\"Hi im the final answer\")\n",
    "    return answer\n",
    "\n",
    "\n",
    "# Define tool node\n",
    "tools = [recommend_recipes, final_answer]\n",
    "tool_node = ToolNode(tools)  # A single node that contains all the tools\n",
    "\n",
    "\n",
    "# Define llm\n",
    "llm = ChatOpenAI().bind_tools(tools)\n",
    "\n",
    "\n",
    "# Define nodes\n",
    "def router(state: MessagesState):\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return \"end\"\n",
    "\n",
    "\n",
    "def agent(state: MessagesState):\n",
    "    messages = state[\"messages\"]\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# Define graph\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "workflow.add_node(\"agent\", agent)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "workflow.add_edge(START, \"agent\")\n",
    "workflow.add_conditional_edges(\"agent\", router, {\"tools\": \"tools\", \"end\": END})\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "\n",
    "# IO\n",
    "def stream_graph_updates(user_input: str):\n",
    "    for event in app.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        stream_graph_updates(user_input)\n",
    "    except:\n",
    "        # fallback if input() is not available\n",
    "        user_input = \"What do you know about LangGraph?\"\n",
    "        print(\"User: \" + user_input)\n",
    "        stream_graph_updates(user_input)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(app.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Has memory but input loop is glitchy (James Briggs implementation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, List, Union\n",
    "from langchain_core.agents import AgentAction, AgentFinish\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.prebuilt import ToolNode\n",
    "import operator\n",
    "\n",
    "\n",
    "# Define state\n",
    "class AgentState(TypedDict):\n",
    "    input: str\n",
    "    # messages: Annotated[list[AnyMessage], add_messages]\n",
    "    chat_history: list[BaseMessage]\n",
    "    intermediate_steps: Annotated[list[tuple[AgentAction, str]], operator.add]\n",
    "\n",
    "\n",
    "# Define tools\n",
    "@tool\n",
    "def recommend_recipes(q: str) -> str:\n",
    "    \"\"\"Takes in user input, extracts relevant features, and output recommended recipes from database\"\"\"\n",
    "\n",
    "    print(f\"\\n Parsed user input: \\n {q} \\n\")\n",
    "\n",
    "    extracted_features = extract_nutritional_features(q)\n",
    "\n",
    "    print(f\"\\n Extracted features: \\n {extracted_features} \\n\")\n",
    "\n",
    "    recs = index.recommend_recipes(\n",
    "        user_ingredients=extracted_features.user_ingredients,\n",
    "        allergens=extracted_features.allergens,\n",
    "        calories=extracted_features.calories,\n",
    "        total_fat=extracted_features.total_fat,\n",
    "        protein=extracted_features.protein,\n",
    "        saturated_fat=extracted_features.saturated_fat,\n",
    "        carbs=extracted_features.carbs,\n",
    "        sodium=extracted_features.sodium,\n",
    "        sugar=extracted_features.sugar,\n",
    "        top_n=10,\n",
    "    )\n",
    "\n",
    "    print(f\"\\n recs: \\n {recs} \\n\")\n",
    "\n",
    "    return \", \".join(recs)\n",
    "\n",
    "\n",
    "@tool\n",
    "def final_answer(answer: str) -> str:\n",
    "    \"\"\"Useful for providing the final answer to the user.\"\"\"\n",
    "    print(\"Hi im the final answer\")\n",
    "    return answer\n",
    "\n",
    "\n",
    "# Define tool node\n",
    "tools = [recommend_recipes, final_answer]\n",
    "tool_node = ToolNode(tools)  # A single node that contains all the tools\n",
    "\n",
    "\n",
    "# Define llm\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "\n",
    "# Define prompt\n",
    "system_prompt = \"\"\"You are the oracle, the great AI decision maker.\n",
    "Given the user's query you must decide what to do with it based on the\n",
    "list of tools provided to you.\n",
    "\n",
    "You are also recipe recommendation program that takes in user inputs\n",
    "and outputs a list of recipes. If a user does not provide enough information\n",
    "on what recipes they want, you will keep on asking them about it until\n",
    "you have enough information to get a good recommendation for the user.\n",
    "\n",
    "If you see that a tool has been used (in the scratchpad) with a particular\n",
    "query, do NOT use that same tool with the same query again. Also, do NOT use\n",
    "any tool more than twice (ie, if the tool appears in the scratchpad twice, do\n",
    "not use it again).\n",
    "\n",
    "You should aim to collect information from a diverse range of sources before\n",
    "providing the answer to the user. Once you have collected plenty of information\n",
    "to answer the user's question (stored in the scratchpad) use the final_answer\n",
    "tool.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "        (\"assistant\", \"scratchpad: {scratchpad}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Define scratchpad\n",
    "def create_scratchpad(intermediate_steps: list[AgentAction]):\n",
    "    \"\"\"\n",
    "    Creates a scratchpad displaying the step-by-step input and output between Human and Agent Messsages.\n",
    "    \"\"\"\n",
    "    research_steps = []\n",
    "    for i, action in enumerate(intermediate_steps):\n",
    "        if action.log != \"TBD\":\n",
    "            # this was the ToolExecution\n",
    "            research_steps.append(\n",
    "                f\"Tool: {action.tool}, input: {action.tool_input}\\n\"\n",
    "                f\"Output: {action.log}\"\n",
    "            )\n",
    "    return \"\\n---\\n\".join(research_steps)\n",
    "\n",
    "\n",
    "# Define agent\n",
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "        \"scratchpad\": lambda x: create_scratchpad(\n",
    "            intermediate_steps=x[\"intermediate_steps\"]\n",
    "        ),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm.bind_tools(tools, tool_choice=\"any\")\n",
    ")\n",
    "\n",
    "# Test run\n",
    "inputs = {\n",
    "    \"input\": \"please give me a breakfast recipe with eggs\",\n",
    "    \"chat_history\": [],\n",
    "    \"intermediate_steps\": [],\n",
    "}\n",
    "out = agent.invoke(inputs)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_node(state: list):\n",
    "    print(\"run_agent\")\n",
    "    print(f\"intermediate_steps: {state['intermediate_steps']}\")\n",
    "    out = agent.invoke(state)\n",
    "    tool_name = out.tool_calls[0][\"name\"]  # Get name of tool\n",
    "    tool_args = out.tool_calls[0][\"args\"]  # Get args that were passed to the tool\n",
    "    action_out = AgentAction(tool=tool_name, tool_input=tool_args, log=\"TBD\")\n",
    "    return {\"intermediate_steps\": [action_out]}\n",
    "\n",
    "\n",
    "def router(state: list):\n",
    "    # return the tool name to use\n",
    "    if isinstance(state[\"intermediate_steps\"], list):\n",
    "        return state[\"intermediate_steps\"][-1].tool\n",
    "    else:\n",
    "        # if we output bad format go to final answer\n",
    "        print(\"Router invalid format\")\n",
    "        return \"final_answer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_str_to_func = {\n",
    "    \"recommend_recipes\": recommend_recipes,\n",
    "    \"final_answer\": final_answer,\n",
    "}\n",
    "\n",
    "\n",
    "def tools_node(state: list):\n",
    "    # use this as helper function so we repeat less code\n",
    "    tool_name = state[\"intermediate_steps\"][-1].tool\n",
    "    tool_args = state[\"intermediate_steps\"][-1].tool_input\n",
    "    print(f\"{tool_name}.invoke(input={tool_args})\")\n",
    "    # run tool\n",
    "    out = tool_str_to_func[tool_name].invoke(input=tool_args)\n",
    "    action_out = AgentAction(tool=tool_name, tool_input=tool_args, log=str(out))\n",
    "    return {\"intermediate_steps\": [action_out]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"agent\", agent_node)\n",
    "graph.add_node(\"recommend_recipes\", tools_node)\n",
    "graph.add_node(\"final_answer\", tools_node)\n",
    "\n",
    "graph.set_entry_point(\"agent\")\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    source=\"agent\",  # where in graph to start\n",
    "    path=router,  # function to determine which node is called\n",
    ")\n",
    "\n",
    "# create edges from each tool back to the oracle\n",
    "for tool_obj in tools:\n",
    "    if tool_obj.name != \"final_answer\":\n",
    "        graph.add_edge(tool_obj.name, \"agent\")\n",
    "\n",
    "# if anything goes to final answer, it must then move to END\n",
    "graph.add_edge(\"final_answer\", END)\n",
    "\n",
    "runnable = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(runnable.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = runnable.invoke(\n",
    "    {\n",
    "        \"input\": \"i want a chicken rice recipe with calories between 0-2000, total fat between 0-1000, saturated fat between 0-1000, carbs between 0-1000, sugar between 0-200, sodium between 0-500mg, and protein between 0-200\",\n",
    "        \"chat_history\": [\"Im allergic to tree nuts\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"\\n\\nFinal output:\")\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[\"intermediate_steps\"][-1].tool_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[\"intermediate_steps\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "\n",
    "def stream_graph_updates(user_input: str, state: AgentState):\n",
    "    state[\"chat_history\"].append(HumanMessage(content=user_input))\n",
    "\n",
    "    for event in runnable.stream(state):\n",
    "        for value in event.values():\n",
    "            assistant_message = value[\"chat_history\"][-1].content\n",
    "            print(\"Assistant:\", assistant_message)\n",
    "            state[\"chat_history\"].append(AIMessage(content=assistant_message))\n",
    "\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        # Initialize state if first interaction\n",
    "        if \"state\" not in locals():\n",
    "            state = {\"input\": user_input, \"chat_history\": [], \"intermediate_steps\": []}\n",
    "\n",
    "        print(state)\n",
    "\n",
    "        stream_graph_updates(user_input, state)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize state\n",
    "state: AgentState = {\n",
    "    \"input\": \"\",\n",
    "    \"chat_history\": [],\n",
    "    \"intermediate_steps\": [],\n",
    "}\n",
    "\n",
    "\n",
    "def stream_graph_updates(user_input: str, state: AgentState):\n",
    "    try:\n",
    "        # Update input\n",
    "        state[\"input\"] = user_input\n",
    "        chat_history_input = HumanMessage(content=user_input)\n",
    "        print(f\"chat_history_input: {chat_history_input}\")\n",
    "        state[\"chat_history\"].append(chat_history_input)\n",
    "        print(f\"state: {state}\")\n",
    "\n",
    "        # Stream response from runnable\n",
    "        for event in runnable.invoke(state):\n",
    "            print(\"DEBUG: Received event:\", event)  # Print full event\n",
    "\n",
    "            for key, value in event.items():\n",
    "                print(f\"DEBUG: Key: {key}, Value: {value}\")\n",
    "\n",
    "            for value in event.values():\n",
    "                print(f\"value: {value}\")\n",
    "                print(f\"chat_history in value: {'chat_history' in value}\")\n",
    "                print(f\"value['chat_history']: {value['chat_history']}\")\n",
    "                if \"chat_history\" in value and value[\"chat_history\"]:\n",
    "                    assistant_message = value[\"chat_history\"][-1].content\n",
    "                    print(\"Assistant:\", assistant_message)\n",
    "                    state[\"chat_history\"].append(AIMessage(content=assistant_message))\n",
    "                else:\n",
    "                    print(\"Warning: No chat history found in response!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in stream_graph_updates: {e}\")\n",
    "\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        stream_graph_updates(user_input, state)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in main loop: {e}\")\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FlavorFusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
